import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { UnifiedPromptEngine } from '@/lib/ai/unified-prompt-engine';
import { SafetyScoreCalculator } from '@/lib/ai/safety-score-calculator';
import { ChoiceQuestionGenerator } from '@/lib/ai/choice-question-generator';
import { CompletionDetectionPromptEngine } from '@/lib/ai/completion-detection-prompt';
import { applyConversationWindowing, generateContextSummary } from '@/lib/chat/conversation-utils';
import { calculateOptimalTokens, estimateContextLength } from '@/lib/ai/token-optimizer';
import {
  chatRequestSchema,
  userDiagnosisDataSchema
} from '@/lib/validation/schemas';
import { validateDiagnosisCompleteness } from '@/lib/validation/utils';
import type { ChatMessage, UserDiagnosisData } from '@/types';

// OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    console.log('=== AI Chat API Request Start ===');

    // Log raw request body for debugging
    const requestBodyText = await request.text();
    console.log('ğŸ” Raw request body:', requestBodyText);

    // Re-create request for validation (reserved for future use)
    const _requestForValidation = new Request(request.url, {
      method: request.method,
      headers: request.headers,
      body: requestBodyText
    });

    // Parse and validate request body manually to capture raw errors
    let parsedBody;
    try {
      parsedBody = JSON.parse(requestBodyText);
    } catch (error) {
      console.log('âŒ JSON Parse failed:', error);
      return NextResponse.json({
        success: false,
        error: 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ',
        code: 'INVALID_JSON'
      }, { status: 400 });
    }

    // Direct schema validation to see raw errors
    const directValidation = chatRequestSchema.safeParse(parsedBody);

    if (!directValidation.success) {
      console.log('âŒ Direct validation failed - raw Zod errors:');
      console.log('ğŸ” Validation errors (first 10):', directValidation.error.errors.slice(0, 10));
      console.log('ğŸ” Error paths and messages:', directValidation.error.errors.map(err => ({
        path: err.path.join('.'),
        message: err.message,
        code: err.code,
        received: 'received' in err ? err.received : 'N/A'
      })));

      return NextResponse.json({
        success: false,
        error: 'ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ',
        details: directValidation.error.errors.slice(0, 5),
        code: 'VALIDATION_ERROR'
      }, { status: 400 });
    }

    console.log('âœ… Validation successful');

    const {
      messages,
      systemPrompt: _clientSystemPrompt, // Reserved for custom system prompts
      userData: diagnosisData,
      stream = false
    } = directValidation.data;

    console.log('ğŸ”„ Processing request data...');
    console.log('ğŸ“ Messages count:', messages.length);
    console.log('ğŸ‘¤ Diagnosis data present:', !!diagnosisData);
    console.log('ğŸ” Raw diagnosisData received from frontend:', diagnosisData);
    console.log('ğŸ” diagnosisData type:', typeof diagnosisData);
    console.log('ğŸ” diagnosisData is null:', diagnosisData === null);
    console.log('ğŸ” diagnosisData is undefined:', diagnosisData === undefined);

    // Deep diagnosis data validation as per Codex recommendations
    if (diagnosisData) {
      console.log('ğŸ”¬ Deep diagnosis data analysis:');
      console.log('  ğŸ“‹ Basic info:', {
        hasName: !!diagnosisData.basic?.name,
        hasAge: !!diagnosisData.basic?.age,
        hasEmail: !!diagnosisData.basic?.email,
        hasGender: !!diagnosisData.basic?.gender,
        hasBirthdate: !!diagnosisData.basic?.birthdate
      });
      console.log('  ğŸ§  MBTI:', {
        hasType: !!diagnosisData.mbti?.type,
        hasSource: !!diagnosisData.mbti?.source
      });
      console.log('  ğŸƒ Taiheki:', {
        hasPrimary: !!diagnosisData.taiheki?.primary,
        hasScores: !!diagnosisData.taiheki?.scores,
        hasCharacteristics: !!diagnosisData.taiheki?.characteristics
      });
      console.log('  ğŸ”® Fortune:', {
        hasZodiac: !!diagnosisData.fortune?.zodiac,
        hasAnimal: !!diagnosisData.fortune?.animal,
        hasSixStar: !!diagnosisData.fortune?.sixStar
      });
      console.log('  ğŸ“Š Progress:', {
        hasProgress: !!diagnosisData.progress,
        step: diagnosisData.progress?.step
      });

      // Test userDiagnosisDataSchema validation directly
      const userSchemaTest = userDiagnosisDataSchema.safeParse(diagnosisData);
      console.log('ğŸ§ª UserDiagnosisDataSchema test:', {
        success: userSchemaTest.success,
        errorCount: userSchemaTest.success ? 0 : userSchemaTest.error.errors.length
      });

      if (!userSchemaTest.success) {
        console.log('âŒ Schema validation errors:', userSchemaTest.error.errors.slice(0, 5));
      }
    }

    // Default values for missing variables
    const usePsychologicalSafety = true; // Enable psychological safety by default
    const topic = 'å¿ƒç†è¨ºæ–­ç›¸è«‡'; // Default topic for diagnosis consultation
    const priority = 'quality'; // Default to quality over speed

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“' },
        { status: 500 }
      );
    }

    // è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã®è©³ç´°æ¤œè¨¼
    if (diagnosisData) {
      console.log('ğŸ“Š Diagnosis data provided, checking completeness...');

      const completenessData = {
        mbti: !!diagnosisData.mbti?.type,
        taiheki: !!diagnosisData.taiheki?.primary,
        fortune: !!diagnosisData.fortune?.animal,
        age: diagnosisData.basic?.age || 0,
        name: diagnosisData.basic?.name || ''
      };

      console.log('ğŸ” Completeness data:', completenessData);

      // è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ã®å®Œæ•´æ€§ã‚’ãƒã‚§ãƒƒã‚¯
      const completenessCheck = validateDiagnosisCompleteness(completenessData);

      console.log('ğŸ” Completeness check result:', completenessCheck);

      if (!completenessCheck.canProceedToChat) {
        console.log('âŒ Incomplete diagnosis data, returning 400');
        return NextResponse.json({
          success: false,
          error: 'è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã™ã€‚ãƒãƒ£ãƒƒãƒˆã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ä»¥ä¸‹ã®è¨ºæ–­ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚',
          details: {
            missingFields: completenessCheck.missingFields,
            canProceed: completenessCheck.canProceedToChat,
            suggestions: [
              'MBTIè¨ºæ–­ã‚’å®Œäº†ã—ã¦ãã ã•ã„',
              'ä½“ç™–è¨ºæ–­ã‚’å®Œäº†ã—ã¦ãã ã•ã„',
              'åŸºæœ¬æƒ…å ±ï¼ˆãŠåå‰ãƒ»å¹´é½¢ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„'
            ]
          },
          code: 'INCOMPLETE_DIAGNOSIS_DATA'
        }, { status: 400 });
      }
    } else {
      return NextResponse.json({
        success: false,
        error: 'çµ±åˆè¨ºæ–­ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚è¨ºæ–­ã‚’å®Œäº†ã—ã¦ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚',
        code: 'MISSING_DIAGNOSIS_DATA'
      }, { status: 400 });
    }

    // Performance: Apply conversation windowing to prevent unlimited growth
    const { windowedMessages, droppedCount, contextInfo } = applyConversationWindowing(messages as ChatMessage[]);
    const contextSummary = generateContextSummary(windowedMessages);

    let systemPrompt: string;
    let maxTokens: number;
    let temperature: number;
    let safetyData: any = null;
    let choiceQuestion: any = null;

    // Phase 2: çµ‚äº†åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
    let completionEngine: CompletionDetectionPromptEngine | null = null;
    if (diagnosisData) {
      const initialConcern = CompletionDetectionPromptEngine.extractInitialConcern(
        diagnosisData as UserDiagnosisData
      );

      completionEngine = new CompletionDetectionPromptEngine({
        diagnosisData: diagnosisData as UserDiagnosisData,
        initialConcern
      });
    }

    // === çµ±ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨ ===

    // 1. å¿ƒç†çš„å®‰å…¨æ€§ã‚¹ã‚³ã‚¢è¨ˆç®— (reserved for future safety metrics)
    const _safetyScore = SafetyScoreCalculator.calculateSafetyScore(windowedMessages);

    // 2. çµ±ä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    const unifiedEngine = new UnifiedPromptEngine(diagnosisData as import('@/types').UserDiagnosisData);
    const psychoPrompt = unifiedEngine.generatePrompt(windowedMessages);

    // 3. é¸æŠå¼è³ªå•ç”Ÿæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    const questionGenerator = new ChoiceQuestionGenerator(diagnosisData as import('@/types').UserDiagnosisData);

    // è³ªå•ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦é¸æŠå¼è³ªå•ã‚’ç”Ÿæˆ
    if (psychoPrompt.questionType === 'choice' || psychoPrompt.questionType === 'hybrid') {
      const _extractedTopics = windowedMessages
        .filter(msg => msg.role === 'user')
        .map(msg => msg.content)
        .join(' '); // Reserved for topic extraction feature

      choiceQuestion = questionGenerator.generateChoiceQuestion(
        psychoPrompt.stage,
        windowedMessages,
        [] // previous topics - could be extracted from conversation history
      );
    }

    // Rogers 3æ¡ä»¶ã«åŸºã¥ãã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨
    systemPrompt = psychoPrompt.systemPrompt;

    // Phase 2: çµ‚äº†åˆ¤å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
    if (completionEngine) {
      systemPrompt += '\n\n' + completionEngine.generateSystemPrompt();
    }

    // Dynamic token optimization based on conversation stage and context
    const contextLength = estimateContextLength(windowedMessages);
    const tokenOptimization = calculateOptimalTokens({
      conversation_stage: psychoPrompt.stage.stage,
      message_count: windowedMessages.length,
      context_length: contextLength,
      priority: 'quality'
    });

    maxTokens = tokenOptimization.maxTokens;
    temperature = 0.8; // æ¸©ã‹ã„å…±æ„Ÿçš„ãªå¿œç­”ã®ãŸã‚å°‘ã—é«˜ã‚

    console.log('Token Optimization:', {
      stage: psychoPrompt.stage.stage,
      contextLength,
      calculatedTokens: maxTokens,
      reasoning: tokenOptimization.reasoning,
      estimatedCost: `$${tokenOptimization.costEstimate.toFixed(6)}`
    });

    safetyData = {
      safetyScore: psychoPrompt.safetyScore,
      stage: psychoPrompt.stage,
      questionType: psychoPrompt.questionType,
      recoveryActions: psychoPrompt.recoveryActions
    };

    // Performance monitoring logs
    console.log('Performance Metrics:', {
      originalMessages: messages.length,
      windowedMessages: windowedMessages.length,
      droppedCount,
      compressionRatio: contextInfo.compressionRatio,
      estimatedTokens: contextSummary.estimatedTokens,
      dynamicTokenLimit: maxTokens,
      usePsychologicalSafety,
      safetyScore: safetyData?.safetyScore?.overall || 'N/A'
    });

    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
    if (stream) {
      const enhancedMessages = [
        { role: 'system' as const, content: systemPrompt },
        ...windowedMessages
      ];

      const response = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: enhancedMessages,
        stream: true,
        temperature,
        max_tokens: maxTokens,
      });

      // ReadableStreamã‚’ä½œæˆï¼ˆå¿ƒç†çš„å®‰å…¨æ€§ãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚€ï¼‰
      const encoder = new TextEncoder();
      const readable = new ReadableStream({
        async start(controller) {
          try {
            // æœ€åˆã«å¿ƒç†çš„å®‰å…¨æ€§ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
            if (safetyData || choiceQuestion) {
              const metaData = {
                type: 'metadata',
                safetyData,
                choiceQuestion,
                windowingInfo: {
                  droppedCount,
                  compressionRatio: contextInfo.compressionRatio
                }
              };
              controller.enqueue(encoder.encode(`data: ${JSON.stringify(metaData)}

`));
            }

            for await (const chunk of response) {
              const delta = chunk.choices[0]?.delta;
              if (delta?.content) {
                const data = {
                  type: 'content',
                  choices: [{
                    delta: {
                      content: delta.content
                    }
                  }]
                };
                controller.enqueue(encoder.encode(`data: ${JSON.stringify(data)}

`));
              }
            }
            controller.enqueue(encoder.encode('data: [DONE]\n\n'));
            controller.close();
          } catch (error) {
            console.error('ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼:', error);
            controller.error(error);
          }
        }
      });

      return new Response(readable, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      });
    }

    // é€šå¸¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
    const enhancedMessages = [
      { role: 'system' as const, content: systemPrompt },
      ...windowedMessages
    ];

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: enhancedMessages,
      temperature,
      max_tokens: maxTokens,
    });

    const content = response.choices[0]?.message?.content || '';

    // Phase 2: çµ‚äº†åˆ¤å®šçµæœã‚’è§£æ
    let completionDetection: any = null;
    if (completionEngine) {
      const parsed = CompletionDetectionPromptEngine.parseCompletionDetection(content);
      if (parsed) {
        completionDetection = {
          resolved: parsed.resolved,
          confidence: parsed.confidence,
          nextAction: parsed.nextAction,
          shouldShowContinueButton: parsed.resolved && parsed.confidence >= 0.8
        };
        console.log('[CompletionDetection] Parsed result:', completionDetection);
      }
    }

    return NextResponse.json({
      message: content,
      usage: response.usage,
      metadata: {
        maxTokens,
        temperature,
        usePsychologicalSafety,
        windowingInfo: {
          droppedCount,
          compressionRatio: contextInfo.compressionRatio
        }
      },
      safetyData,
      choiceQuestion,
      completionDetection // Phase 2: æ–°è¦ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ 
    });

  } catch (error) {
    console.error('OpenAI API ã‚¨ãƒ©ãƒ¼:', error);

    if (error instanceof Error) {
      return NextResponse.json(
        { error: `AIå¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error.message}` },
        { status: 500 }
      );
    }

    return NextResponse.json(
      { error: 'AIå¿œç­”ã®ç”Ÿæˆä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ' },
      { status: 500 }
    );
  }
}